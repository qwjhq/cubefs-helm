# Select which component to install
  namespace:
component:
  master: true
  datanode: true
  metanode: true
  objectnode: true
  client: true
  lcnode: true
  dashboard: true
  csi: false
  monitor: false
  ingress: false
  blobstore_clustermgr: false
  blobstore_blobnode: false
  blobstore_proxy: false
  blobstore_scheduler: false
  blobstore_access: false

# Allow to override kubernetes version
kubernetes:
  version: ""

image:
  server: cubefs/cfs-server:v3.5.2
  client: cubefs/cfs-client:v3.5.2
  blobstore: cubefs/blobstore:v3.4.0
  dashboard: cubefs/cubefs-dashboard:v2

  # CSI related images
  csi_driver: cubefs/cfs-csi-driver:v3.5.2
  csi_provisioner: registry.k8s.io/sig-storage/csi-provisioner:v2.2.2
  csi_attacher: registry.k8s.io/sig-storage/csi-attacher:v3.4.0
  csi_resizer: registry.k8s.io/sig-storage/csi-resizer:v1.3.0
  driver_registrar: registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.5.0

  grafana: grafana/grafana:6.4.4
  prometheus: prom/prometheus:v2.13.1
  consul: consul:1.6.1
  pull_policy: "IfNotPresent"
  pull_secrets: []

log:
  # Do not redirect the standard output into a file, recommend to
  # set to true, but cfs-server version > 3.2.0 was required
  do_not_redirect_std: false

# store data,log and other data, these directory will be
#  mounted from host to container using hostPath
path:
  data: /var/lib/cubefs
  log: /var/log/cubefs
  monitor: /var/lib/cubefs_prometheus

master:
  # The replicas of master component, at least 3, recommend to be an odd number
  replicas: 3
  # Cluster name
  cluster: my-cluster
  # NodeSelector
  nodeSelector:
    "component.cubefs.io/master": "enabled"
  tolerations: [ ]
  host: master.cubefs.com
  log_level: error
  retain_logs: 2000
  # Master service http port
  port: 17010
  # Master golang pprof port
  prof: 17020
  exporter_port: 9500
  # Reserved memory in bytes for each metanode, if available memory less than this value, the metanode will be unwritable
  metanode_reserved_mem: "67108864"
  metanode_threshold_mem_rate: "0.98" # default 75% metanode memory usage will not work, set 98%
  legacy_data_media_type: "2" # version upgrate >= v3.5.1, old cluster disk media type hdd 2, ssd 1
  resources:
    enabled: true
    requests:
      memory: "4Gi"
      cpu: "2"
    limits:
      memory: "16Gi"
      cpu: "8"

metanode:
  # NodeSelector for metanode daemonset
  nodeSelector:
    "component.cubefs.io/metanode": "enabled"
  tolerations: [ ]
  log_level: error
  # Total memory metanode can use, recommended to be configured
  # as 80% of physical machine memory
  total_mem: "107374182400" # 100G
  port: 17210
  prof: 17220
  raft_heartbeat: 17230
  raft_replica: 17240
  exporter_port: 9510
  resources:
    enabled: true
    requests:
      memory: "32Gi"
      cpu: "2"
    limits:
      memory: "100Gi"
      cpu: "12"

datanode:
  # NodeSelector for datanode daemonset
  nodeSelector:
    "component.cubefs.io/datanode": "enabled"
  tolerations: [ ]
  log_level: error
  port: 17310
  prof: 17320
  raft_heartbeat: 17330
  raft_replica: 17340
  exporter_port: 9520
  # Disks will be used by datanode to storage data
  # Format: disk_mount_point:reserved_space
  # disk_mount_point: the mount point of disk in machine
  # reserved_space: similar to metanode reserved space, if disk available
  # space less than this number, then the disk will be unwritable
  # 5GB
  disks:
    - "/data1:5368709120"
    - "/data2:5368709120"
  mediaType: 2 # hdd 2 ssd 1
  resources:
    enabled: true
    requests:
      memory: "4Gi"
      cpu: "2"
    limits:
      memory: "64Gi"
      cpu: "8"


objectnode:
  # The replicas of object component, object node is stateless,
  # it can be any number depending on your traffic magnitude.
  replicas: 3
  log_level: error
  port: 1601
  prof: 7011
  exporter_port: 9500
  nodeSelector:
    "component.cubefs.io/objectnode": "enabled"
  tolerations: [ ]
  region: "spark"
  # Domains listed here will be used in resolution of pan-domain names to parse bucket name
  domains:
    - "objectcfs.cubefs.io"
    - "objectnode.cubefs.io"
  host: objectnode.cubefs.com
  resources:
    enabled: true
    requests:
      memory: "1Gi"
      cpu: "1"
    limits:
      memory: "8Gi"
      cpu: "4"

client:
  replicas: 1
  vol_name: "test"
  owner: "cubefs"
  log_level: error
  exporter_port: 9530
  prof: 17410
  resources:
    enabled: true
    requests:
      memory: "512Mi"
      cpu: "500m"
    limits:
      memory: "1024Mi"
      cpu: "1000m"

lcnode:
  replicas: 3
  log_level: error
  port: 80
  prof: 7011
  exporter_port: 9500
  nodeSelector:
    "component.cubefs.io/lcnode": "enabled"
  tolerations: [ ]
  resources:
    enabled: true
    requests:
      memory: "512Mi"
      cpu: "500m"
    limits:
      memory: "1024Mi"
      cpu: "1000m"

dashboard:
  replicas: 1
  port: 80
  mysql_host: 127.0.0.1
  mysql_port: 3306
  mysql_slave_host: 127.0.0.1
  mysql_slave_port: 3306
  mysql_user: cubefs
  mysql_pwd: 
  mysql_db: cubefs
  tolerations: [ ]
  resources:
    enabled: true
    requests:
      memory: "512Mi"
      cpu: "500m"
    limits:
      memory: "1024Mi"
      cpu: "1000m"

csi:
  driverName: csi.cubefs.com
  logLevel: error
  # If you changed the default kubelet home path, this
  # value needs to be modified accordingly
  kubeletPath: /var/lib/kubelet
  controller:
    tolerations: [ ]
    nodeSelector:
      "node-role.kubernetes.io/cfs-csi": "true"
  node:
    tolerations: [ ]
    nodeSelector:
      "node-role.kubernetes.io/cfs-csi": "true"
    resources:
      enabled: false
      requests:
        memory: "4048Mi"
        cpu: "2000m"
      limits:
        memory: "4048Mi"
        cpu: "2000m"
  storageClass:
    # Whether automatically set this StorageClass to default volume provisioner
    setToDefault: true
    # StorageClass reclaim policy, 'Delete' or 'Retain' is supported
    reclaimPolicy: "Delete"
    # Override the master address parameter to connect to external cluster
    masterAddr: ""
    otherParameters:
    # Other parameters that will pass through to StorageClass, and then
    # will pass through to the generated cfs-client configuration file.
    # crossZone: "false"
    # enableToken: "false"
    # zoneName: ""
    # icacheTimeout: ""
    # lookupValid: ""
    # attrValid: ""
    # readRate: ""
    # writeRate: ""
    # enSyncWrite: ""
    # autoInvalData: ""
    # rdonly: "false"
    # writecache: "false"
    # keepcache: "false"
    # followerRead: "false"
    # authenticate: "false"
    # clientKey: ""
    # ticketHost: ""
    # enableHTTPS: "false"
    # token: ""
    # accessKey: ""
    # secretKey: ""
    # disableDcache: "false"
    # subdir: ""
    # fsyncOnClose: "true"
    # maxcpus: ""
    # enableXattr: "false"
    # alignSize: "4096"
    # maxExtentNumPerAlignArea: "12"
    # forceAlignMerge: "true"

consul:
  port: 8500
  replicas: 1
  external_address: ""

grafana:
  port: 3000
  replicas: 1
  # Ingress host name
  host: monitor.cubefs.com
  admin_password: !!string 123456
  resources:
    enabled: false
    requests:
      memory: "512Mi"
      cpu: "500m"
    limits:
      memory: "1024Mi"
      cpu: "1000m"

prometheus:
  port: 9090
  replicas: 1
  resources:
    enabled: false
    requests:
      memory: "512Mi"
      cpu: "500m"
    limits:
      memory: "1024Mi"
      cpu: "1000m"

blobstore_clustermgr:
  replicas: 3
  port: 9998
  nodeSelector:
    "component.cubefs.io/clustermgr": "enabled"
  tolerations: [ ]
  bind_addr: ":9998"
  cluster_id: "1"
  idc: '["z0"]'
  chunk_size: "16777216"
  log_level: "info"
  enable_auth: "false"
  auth_secret: "test-secret"
  region: "test-region"
  code_policies: '[{"mode_name":"EC3P3","min_size":0,"max_size":5368709120,"size_ratio":1,"enable":true}]'
  raft_port: 10110
  alloc_size: "1048576"
  raft_snapshot_num: "64"
  raft_flush_num: "10000"
  raft_flush_interval: "10"
  raft_trunc_num: "10"
  disk_refresh_interval: "10"
  disk_rack_aware: "false"
  disk_host_aware: "false"
  db_path: "/var/lib/blobstore-clustermgr-db"
  wal_path: "/var/lib/blobstore-clustermgr-wal"
  log_path: "/var/log/blobstore-clustermgr"

blobstore_blobnode:
  port: 8899
  bind_addr: ":8899"
  nodeSelector:
    "component.cubefs.io/blobnode": "enabled"
  tolerations: [ ]
  cluster_id: "1"
  idc: "z0"
  rack: "testrack"
  log_level: "info"
  disk_reserved: "1"
  compact_reserved: "1"
  log_path: "/var/log/blobstore-blobnode"
  disks:
    - /var/log/blobstore-blobnode-disk1:/cfs/data/disk1

blobstore_proxy:
  port: 9600
  bind_addr: ":9600"
  nodeSelector:
    "component.cubefs.io/proxy": "enabled"
  tolerations: [ ]
  cluster_id: "1"
  idc: "z0"
  log_level: "info"
  alloc_vols_num: 2
  hb_interval: 3
  kafka_addrs: "kafka-service:9092"
  cache_path: "/var/lib/blobstore-proxy-cache"
  log_path: "/var/log/blobstore-proxy"

blobstore_scheduler:
  replicas: 2
  port: 9800
  bind_addr: ":9800"
  nodeSelector:
    "component.cubefs.io/scheduler": "enabled"
  tolerations: [ ]
  cluster_id: "1"
  idc: "z0"
  log_level: "info"
  kafka_addrs: "kafka-service:9092"
  log_path: "/var/log/blobstore-scheduler"

blobstore_access:
  port: 9500
  bind_addr: ":9500"
  nodeSelector:
    "component.cubefs.io/access": "enabled"
  tolerations: [ ]
  cluster_id: "1"
  idc: "z0"
  region: "test-region"
  log_level: "info"
  log_path: "/var/log/blobstore-access"
